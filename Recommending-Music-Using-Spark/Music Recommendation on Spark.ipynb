{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data and inspect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-05-09 15:47:31--  http://www.iro.umontreal.ca/~lisa/datasets/profiledata_06-May-2005.tar.gz\n",
      "Resolving www.iro.umontreal.ca (www.iro.umontreal.ca)... 132.204.26.36\n",
      "Connecting to www.iro.umontreal.ca (www.iro.umontreal.ca)|132.204.26.36|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 135880312 (130M) [application/x-gzip]\n",
      "Saving to: ‘data/profiledata_06-May-2005.tar.gz’\n",
      "\n",
      "profiledata_06-May- 100%[===================>] 129.58M  89.6MB/s    in 1.4s    \n",
      "\n",
      "2018-05-09 15:47:33 (89.6 MB/s) - ‘data/profiledata_06-May-2005.tar.gz’ saved [135880312/135880312]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "!wget \"http://www.iro.umontreal.ca/~lisa/datasets/profiledata_06-May-2005.tar.gz\" -P data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\r\n",
      "└── [130M]  profiledata_06-May-2005.tar.gz\r\n",
      "\r\n",
      "0 directories, 1 file\r\n"
     ]
    }
   ],
   "source": [
    "!tree data -hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\r\n",
      "└── [4.0K]  profiledata_06-May-2005\r\n",
      "    ├── [2.8M]  artist_alias.txt\r\n",
      "    ├── [ 53M]  artist_data.txt\r\n",
      "    ├── [1.2K]  README.txt\r\n",
      "    └── [407M]  user_artist_data.txt\r\n",
      "\r\n",
      "1 directory, 4 files\r\n"
     ]
    }
   ],
   "source": [
    "!tar -xf \"data/profiledata_06-May-2005.tar.gz\" -C data\n",
    "!rm \"data/profiledata_06-May-2005.tar.gz\"\n",
    "!tree data -hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Music Listening Dataset\r\n",
      "Audioscrobbler.com\r\n",
      "6 May 2005\r\n",
      "--------------------------------\r\n",
      "\r\n",
      "This data set contains profiles for around 150,000 real people\r\n",
      "The dataset lists the artists each person listens to, and a counter\r\n",
      "indicating how many times each user played each artist\r\n",
      "\r\n",
      "The dataset is continually growing; at the time of writing (6 May 2005) \r\n",
      "Audioscrobbler is receiving around 2 million song submissions per day\r\n",
      "\r\n",
      "We may produce additional/extended data dumps if anyone is interested \r\n",
      "in experimenting with the data. \r\n",
      "\r\n",
      "Please let us know if you do anything useful with this data, we're always\r\n",
      "up for new ways to visualize it or analyse/cluster it etc :)\r\n",
      "\r\n",
      "\r\n",
      "License\r\n",
      "-------\r\n",
      "\r\n",
      "This data is made available under the following Creative Commons license:\r\n",
      "http://creativecommons.org/licenses/by-nc-sa/1.0/\r\n",
      "\r\n",
      "\r\n",
      "Files\r\n",
      "-----\r\n",
      "\r\n",
      "user_artist_data.txt\r\n",
      "    3 columns: userid artistid playcount\r\n",
      "\r\n",
      "artist_data.txt\r\n",
      "    2 columns: artistid artist_name\r\n",
      "\r\n",
      "artist_alias.txt\r\n",
      "    2 columns: badid, goodid\r\n",
      "    known incorrectly spelt artists and the correct artist id. \r\n",
      "    you can correct errors in user_artist_data as you read it in using this file\r\n",
      "    (we're not yet finished merging this data)\r\n",
      "    \r\n",
      "    \r\n",
      "Contact Info\r\n",
      "------------\r\n",
      "rj@audioscrobbler.com\r\n",
      "irc://irc.audioscrobbler.com/audioscrobbler\r\n"
     ]
    }
   ],
   "source": [
    "!cat data/profiledata_06-May-2005/README.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check user_artist_data.txt\n",
      "1000002 1 55\n",
      "1000002 1000006 33\n",
      "1000002 1000007 8\n",
      "\n",
      "line count:\n",
      "24296858 data/profiledata_06-May-2005/user_artist_data.txt\n"
     ]
    }
   ],
   "source": [
    "!echo \"check user_artist_data.txt\"\n",
    "!head -n 3 data/profiledata_06-May-2005/user_artist_data.txt\n",
    "!echo \"\"\n",
    "!echo \"line count:\"\n",
    "!wc -l data/profiledata_06-May-2005/user_artist_data.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check artist_data.txt\n",
      "1134999\t06Crazy Life\n",
      "6821360\tPang Nakarin\n",
      "10113088\tTerfel, Bartoli- Mozart: Don\n",
      "\n",
      "line count:\n",
      "1848579 data/profiledata_06-May-2005/artist_data.txt\n"
     ]
    }
   ],
   "source": [
    "!echo \"check artist_data.txt\"\n",
    "!head -n 3 data/profiledata_06-May-2005/artist_data.txt\n",
    "!echo \"\"\n",
    "!echo \"line count:\"\n",
    "!wc -l data/profiledata_06-May-2005/artist_data.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check artist_alias.txt\n",
      "1092764\t1000311\n",
      "1095122\t1000557\n",
      "6708070\t1007267\n",
      "\n",
      "line count:\n",
      "193027 data/profiledata_06-May-2005/artist_alias.txt\n"
     ]
    }
   ],
   "source": [
    "!echo \"check artist_alias.txt\"\n",
    "!head -n 3 data/profiledata_06-May-2005/artist_alias.txt\n",
    "!echo \"\"\n",
    "!echo \"line count:\"\n",
    "!wc -l data/profiledata_06-May-2005/artist_alias.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Spark Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure pyspark tells workers to use python3 not 2 if both are installed\n",
    "import os\n",
    "os.environ['PYSPARK_PYTHON'] = '/home/augustinus/miniconda3/bin/python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Recommender\") \\\n",
    "    .config('spark.executor.memory','8G') \\\n",
    "    .config('spark.driver.memory','16G')\\\n",
    "    .config('spark.driver.maxResultSize','16G')\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create user_artist DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_artist = spark.read.csv(\"data/profiledata_06-May-2005/user_artist_data.txt\",\n",
    "                                sep=' ',\n",
    "                                schema='userid INT, artistid INT, playcount INT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userid: integer (nullable = true)\n",
      " |-- artistid: integer (nullable = true)\n",
      " |-- playcount: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_user_artist.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+---------+\n",
      "| userid|artistid|playcount|\n",
      "+-------+--------+---------+\n",
      "|1000002|       1|       55|\n",
      "|1000002| 1000006|       33|\n",
      "|1000002| 1000007|        8|\n",
      "+-------+--------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_user_artist.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create artist DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artistid: integer (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      "\n",
      "+--------+--------------------+\n",
      "|artistid|         artist_name|\n",
      "+--------+--------------------+\n",
      "| 1134999|        06Crazy Life|\n",
      "| 6821360|        Pang Nakarin|\n",
      "|10113088|Terfel, Bartoli- ...|\n",
      "+--------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_artist = spark.read.csv(\"data/profiledata_06-May-2005/artist_data.txt\",\n",
    "                            sep='\\t',\n",
    "                            schema='artistid INT, artist_name STRING')\n",
    "df_artist.printSchema()\n",
    "df_artist.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create artist_alias DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- badid: integer (nullable = true)\n",
      " |-- goodid: integer (nullable = true)\n",
      "\n",
      "+-------+-------+\n",
      "|  badid| goodid|\n",
      "+-------+-------+\n",
      "|1092764|1000311|\n",
      "|1095122|1000557|\n",
      "|6708070|1007267|\n",
      "+-------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_artist_alias = spark.read.csv(\"data/profiledata_06-May-2005/artist_alias.txt\",\n",
    "                                sep='\\t',\n",
    "                                schema='badid INT, goodid INT')\n",
    "df_artist_alias.printSchema()\n",
    "df_artist_alias.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+-----------+\n",
      "|database|   tableName|isTemporary|\n",
      "+--------+------------+-----------+\n",
      "|        |      artist|       true|\n",
      "|        |artist_alias|       true|\n",
      "|        | user_artist|       true|\n",
      "+--------+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Register SQL Tables\n",
    "df_user_artist.createOrReplaceTempView('user_artist')\n",
    "df_artist.createOrReplaceTempView('artist')\n",
    "df_artist_alias.createOrReplaceTempView('artist_alias')\n",
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aliases data set should be applied to convert all artist IDs (badid) to a canonical ID (goodid), if a different canonical ID exists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_artist\n",
      "+---------+---------+-------+\n",
      "| col_name|data_type|comment|\n",
      "+---------+---------+-------+\n",
      "|   userid|      int|   null|\n",
      "| artistid|      int|   null|\n",
      "|playcount|      int|   null|\n",
      "+---------+---------+-------+\n",
      "\n",
      "artist\n",
      "+-----------+---------+-------+\n",
      "|   col_name|data_type|comment|\n",
      "+-----------+---------+-------+\n",
      "|   artistid|      int|   null|\n",
      "|artist_name|   string|   null|\n",
      "+-----------+---------+-------+\n",
      "\n",
      "artist_alias\n",
      "+--------+---------+-------+\n",
      "|col_name|data_type|comment|\n",
      "+--------+---------+-------+\n",
      "|   badid|      int|   null|\n",
      "|  goodid|      int|   null|\n",
      "+--------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('user_artist')\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    describe user_artist\n",
    "    \"\"\").show()\n",
    "\n",
    "print('artist')\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    describe artist\n",
    "    \"\"\").show()\n",
    "\n",
    "print('artist_alias')\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    describe artist_alias\n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking artist\n",
      "+---------+------------+----------------+\n",
      "|total_ids|n_unique_ids| ratio of unique|\n",
      "+---------+------------+----------------+\n",
      "|  1848671|     1848281|0.99978903763839|\n",
      "+---------+------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Checking artist')\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select count(*) as total_ids, \n",
    "    count(distinct artistid) as n_unique_ids, \n",
    "    count(distinct artistid)/count(*) as `ratio of unique`\n",
    "    from artist \n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking user_artist\n",
      "+------------------+\n",
      "|n_unique_artistids|\n",
      "+------------------+\n",
      "|           1631028|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Checking user_artist')\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select count(distinct artistid) as n_unique_artistids\n",
    "    from user_artist \n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping badid to goodid for user_artist and artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "alias = df_artist_alias.dropna().toPandas()\n",
    "bad_2_good_mapper = dict(alias[['badid','goodid']].values)\n",
    "# if x is in bad_2_good_mapper: get goodid, otherwise keep x unchanged \n",
    "bad2good = lambda x : bad_2_good_mapper.get(x,x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply bad2good (.map) to the artistid column in df_artist, df_user_artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artist.artistid = df_artist.select('artistid').rdd.map(bad2good).toDF().artistid\n",
    "df_user_artist = df_user_artist.dropna()\n",
    "df_user_artist.artistid = df_user_artist.select('artistid').rdd.map(bad2good).toDF().artistid\n",
    "df_artist.createOrReplaceTempView('artist')\n",
    "df_user_artist.createOrReplaceTempView('user_artist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking artist\n",
      "+---------+------------+----------------+\n",
      "|total_ids|n_unique_ids| ratio of unique|\n",
      "+---------+------------+----------------+\n",
      "|  1848671|     1848281|0.99978903763839|\n",
      "+---------+------------+----------------+\n",
      "\n",
      "Checking user_artist\n",
      "+-----------+\n",
      "|n_artistids|\n",
      "+-----------+\n",
      "|    1631028|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Checking artist')\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select count(*) as total_ids, \n",
    "    count(distinct artistid) as n_unique_ids, \n",
    "    count(distinct artistid)/count(*) as `ratio of unique`\n",
    "    from artist \n",
    "    \"\"\").show()\n",
    "\n",
    "print('Checking user_artist')\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select count(distinct artistid) as n_artistids\n",
    "    from user_artist \n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = spark.sql(\n",
    "    \"\"\"\n",
    "    select userid, artistid, sum(playcount) as playcount\n",
    "    from user_artist\n",
    "    group by userid,artistid\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build ALS Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userid: integer (nullable = true)\n",
      " |-- artistid: integer (nullable = true)\n",
      " |-- playcount: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fitted\n"
     ]
    }
   ],
   "source": [
    "als = ALS(rank=50,regParam=1,alpha=40,\n",
    "          userCol='userid',itemCol='artistid',ratingCol='playcount',\n",
    "          numUserBlocks=4,numItemBlocks=4,implicitPrefs=True,seed=0)\n",
    "\n",
    "als_recommender = als.fit(data_train)\n",
    "print('Model fitted')\n",
    "als_recommender.save('model.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommend top 10 Artists for user 2093760"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "| userid|\n",
      "+-------+\n",
      "|2093760|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_subsets = \\\n",
    "    spark.sql(\"\"\"\n",
    "        select distinct userid\n",
    "        from user_artist\n",
    "        where userid in (2093760)\n",
    "        \"\"\")\n",
    "user_subsets.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userid: integer (nullable = false)\n",
      " |-- recommendations: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- artistid: integer (nullable = true)\n",
      " |    |    |-- rating: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommendations = als_recommender.recommendForUserSubset(user_subsets, 10)\n",
    "recommendations.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations.createOrReplaceTempView('recommendations')\n",
    "\n",
    "top10 = spark.sql(\n",
    "    \"\"\"\n",
    "    select userid, explode(recommendations.artistid) as artistid\n",
    "    from recommendations \n",
    "    where userid = 2093760\n",
    "    \"\"\")\n",
    "top10.createOrReplaceTempView('top10')\n",
    "\n",
    "top10_recommended_artist_names = \\\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select userid, artist_name\n",
    "    from top10 join artist\n",
    "    on top10.artistid = artist.artistid\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>artist_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2093760</td>\n",
       "      <td>Green Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2093760</td>\n",
       "      <td>Outkast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2093760</td>\n",
       "      <td>Eminem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2093760</td>\n",
       "      <td>50 Cent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2093760</td>\n",
       "      <td>Snoop Dogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2093760</td>\n",
       "      <td>Black Eyed Peas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2093760</td>\n",
       "      <td>Jay-Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2093760</td>\n",
       "      <td>2Pac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2093760</td>\n",
       "      <td>Kanye West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2093760</td>\n",
       "      <td>[unknown]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userid      artist_name\n",
       "0  2093760        Green Day\n",
       "1  2093760          Outkast\n",
       "2  2093760           Eminem\n",
       "3  2093760          50 Cent\n",
       "4  2093760       Snoop Dogg\n",
       "5  2093760  Black Eyed Peas\n",
       "6  2093760            Jay-Z\n",
       "7  2093760             2Pac\n",
       "8  2093760       Kanye West\n",
       "9  2093760        [unknown]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top10_artists_for_2093760 = top10_recommended_artist_names.toPandas()\n",
    "df_top10_artists_for_2093760"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy on AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark-submit wordcount.py | tee output.txt\n",
    "aws s3 cp output.txt s3://my_bucket/my_folder/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
